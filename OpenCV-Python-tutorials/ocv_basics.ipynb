{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597326646015",
   "display_name": "Python 3.7.7 64-bit ('Anaconda3': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read image from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"Lenna_(test_image).png\"\n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "cv2.imshow(\"Image from file\", img)  # Display image\n",
    "cv2.waitKey(0)                      # Wait forever until a key is pressed\n",
    "cv2.destroyAllWindows()             # Close all windows, MUST use when run in Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read video from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"tesla_coil.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    \n",
    "    # success is None when no more frame (video ends)\n",
    "    if success:\n",
    "        cv2.imshow(\"Video from file\", img)\n",
    "        # cv2.waitKey(1) will wait for 1ms before moving on\n",
    "        # Press 'q' to stop playback\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read video from webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Set VideoCaptureProperties\n",
    "# Width and Height\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "# See full list here: https://docs.opencv.org/master/d4/d15/group__videoio__flags__base.html#gaeb8dd9c89c10a5c63c139bf7c4f5704d\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    cv2.imshow(\"Video from webcam\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Open-CV functions on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"Lenna_(test_image).png\"\n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply Gaussian blur filter\n",
    "blur = cv2.GaussianBlur(img, (13,13), 0)\n",
    "\n",
    "# Stack grayscale image 3 times to create a 3-channel image\n",
    "gray3 = np.stack((gray,gray,gray), axis=2)\n",
    "# Stack images horizontally\n",
    "output = np.hstack((img, gray3, blur))\n",
    "cv2.imshow('Images', output)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resize and crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_path = \"Lenna_(test_image).png\"\n",
    "img = cv2.imread(img_path)\n",
    "cv2.imshow(\"Original\", img)\n",
    "\n",
    "# Resize (width, height)\n",
    "img = cv2.resize(img, (400,500))\n",
    "cv2.imshow(\"Resized\", img)\n",
    "\n",
    "print('Array format (HWC): ', img.shape)\n",
    "\n",
    "# Crop [Height, Width, Channel] â†’ (HWC) format\n",
    "img = img[200:400, 100:500]\n",
    "cv2.imshow(\"Cropped\", img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw shapes and text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.zeros((512,512,3), np.uint8)\n",
    "\n",
    "cv2.line(img, (0,0), (300,300), (255, 0, 0), 2)\n",
    "cv2.rectangle(img, (100,100), (200,200), (0, 255, 0), 1)\n",
    "cv2.putText(img, \"Open-CV\", (300,200), cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "cv2.imshow(\"Shapes\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a mask from color range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_path = \"Lenna_(test_image).png\"\n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "# Convert to HSV color space\n",
    "# H = [0,179], S = [0,255], V = [0,255]\n",
    "imgHSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "lower = np.array([90,120,0])\n",
    "upper = np.array([160,255,255])\n",
    "\n",
    "# cv2.inRange() will return a 1-channel image, with pixel values either 0 or 255\n",
    "mask = cv2.inRange(imgHSV, lower, upper)\n",
    "\n",
    "# Apply mask\n",
    "img_masked = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "mask3 = np.stack((mask, mask, mask), axis=2)\n",
    "output = np.hstack((img, mask3, img_masked))\n",
    "cv2.imshow(\"Masking\", output)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"Lenna_(test_image).png\"\n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Load pre-trained Cascade Classifier\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Perform face detection\n",
    "faces = face_cascade.detectMultiScale(gray)\n",
    "for (x,y,w,h) in faces:\n",
    "    # Draw bounding box\n",
    "    img = cv2.rectangle(img, (x,y), (x+w,y+h), (255,0,0), 2)\n",
    "\n",
    "cv2.imshow('img',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slider control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Masking code\n",
    "img_path = \"Lenna_(test_image).png\"\n",
    "img = cv2.imread(img_path)\n",
    "imgHSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "lower = np.array([90,0,0])\n",
    "upper = np.array([160,255,255])\n",
    "HUE_RANGE = 80\n",
    "\n",
    "def update_mask(hue=0):\n",
    "    lower[0] = np.max((hue - HUE_RANGE // 2,   0))\n",
    "    upper[0] = np.min((hue + HUE_RANGE // 2, 179))\n",
    "    \n",
    "    mask = cv2.inRange(imgHSV, lower, upper)\n",
    "    img_masked = cv2.bitwise_and(img, img, mask=mask)\n",
    "    mask3 = np.stack((mask, mask, mask), axis=2)\n",
    "    output = np.hstack((img, mask3, img_masked))\n",
    "    cv2.imshow(\"Masking\", output)\n",
    "update_mask()\n",
    "\n",
    "# Add a window named 'Control'\n",
    "cv2.namedWindow('Control')\n",
    "# Create a Trackbar named 'Hue' with callback update_mask\n",
    "cv2.createTrackbar('Hue', 'Control', 0, 179, update_mask)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ]
}